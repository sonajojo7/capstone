{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "# Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import os\n",
    "import configparser\n",
    "import datetime as dt\n",
    "import psycopg2\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import isnan, when, count, col, udf, dayofmonth, dayofweek, month, year, weekofyear\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import requests\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "\n",
    "import utility\n",
    "import functions\n",
    "\n",
    "import importlib\n",
    "importlib.reload(utility)\n",
    "from utility import clean_spark_immigration_data, clean_spark_temperature_data\n",
    "from utility import clean_spark_demographics_data, print_formatted_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['KEYS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['KEYS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "    config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "    enableHiveSupport().getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "The objective of this project is to make analysis on the immigration events based on various datasets obtained. An ETL is to be created for I-94 immigration, global land temperature and US demographics datasets. This is used to get an idea of immigration patterns to US.\n",
    "\n",
    "For example, we could try to find answears to questions such as, do people from countries with warmer or cold climate immigrate to the US in large numbers?\n",
    "Or , Around which states are immigrants more drawn towards ? And so on..\n",
    "#### Immigration Dataset\n",
    "This data comes from the US National Tourism and Trade Office.In the past all foreign visitors to the U.S. arriving via air or sea were required to complete paper Customs and Border Protection Form I-94 Arrival/Departure Record or Form I-94W Nonimmigrant Visa Waiver Arrival/Departure Record and this dataset comes from this forms. This dataset forms the core of the data warehouse and the customer repository has a years worth of data for the year 2016 and the dataset is divided by month. For this project the data is in a folder located at ../../data/18-83510-I94-Data-2016/. Each months data is stored in an SAS binary database storage format sas7bdat. For this project we have chosen going to work with data for the month of April. The data extraction, transformation and loading utility functions have been designed to work with any month's worth of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "immig_name = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "immigration_df =spark.read.format('com.github.saurfang.sas.spark').load(immig_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(cicid=6.0, i94yr=2016.0, i94mon=4.0, i94cit=692.0, i94res=692.0, i94port='XXX', arrdate=20573.0, i94mode=None, i94addr=None, depdate=None, i94bir=37.0, i94visa=2.0, count=1.0, dtadfile=None, visapost=None, occup=None, entdepa='T', entdepd=None, entdepu='U', matflag=None, biryear=1979.0, dtaddto='10282016', gender=None, insnum=None, airline=None, admnum=1897628485.0, fltno=None, visatype='B2')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,096,313\n"
     ]
    }
   ],
   "source": [
    "print_formatted_float(immigration_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|visapost|\n",
      "+--------+\n",
      "|     CRS|\n",
      "|     KGL|\n",
      "|     AKD|\n",
      "|     BGM|\n",
      "|     TRK|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df.select(\"visapost\").dropDuplicates().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### World Temperature Data\n",
    "This dataset came from Kaggle accessible through '../../data2/GlobalLandTemperaturesByCity.csv' . The dataset provides data about global land temperatures by cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0 1743-11-01               6.068                          1.737  Århus   \n",
       "1 1743-12-01                 NaN                            NaN  Århus   \n",
       "2 1744-01-01                 NaN                            NaN  Århus   \n",
       "3 1744-02-01                 NaN                            NaN  Århus   \n",
       "4 1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temperature_df = spark.read.csv(file_name, header=True, inferSchema=True)\n",
    "# display the first five records\n",
    "temperature_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8,599,212\n"
     ]
    }
   ],
   "source": [
    "# check the total number of records\n",
    "print_formatted_float(temperature_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### US Demographic Data\n",
    "This data comes from OpenSoft. It contains information about the demographics of all US cities and census-designated places with a population greater or equal to 65,000. The original data source is the US Census Bureau's 2015 American Community Survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8            40601   \n",
       "1            Quincy  Massachusetts        41.0            44129   \n",
       "2            Hoover        Alabama        38.5            38040   \n",
       "3  Rancho Cucamonga     California        34.5            88127   \n",
       "4            Newark     New Jersey        34.6           138040   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0              41862             82463                1562         30908   \n",
       "1              49500             93629                4147         32935   \n",
       "2              46799             84839                4819          8229   \n",
       "3              87105            175232                5821         33878   \n",
       "4             143873            281913                5829         86253   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"us-cities-demographics.csv\"\n",
    "demographics_df = spark.read.csv(file_name, inferSchema=True, header=True, sep=';')\n",
    "# display the first five records\n",
    "demographics_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,891\n"
     ]
    }
   ],
   "source": [
    "# check the total number of records\n",
    "print_formatted_float(demographics_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder.\\\n",
    "# config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "# config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "# enableHiveSupport().getOrCreate()\n",
    "\n",
    "# df_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# #write to parquet\n",
    "# df_spark.write.parquet(\"sas_data\")\n",
    "# df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data\n",
    "\n",
    "### 1.Immigration dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i94_apr16_sub.sas7bdat',\n",
       " 'i94_sep16_sub.sas7bdat',\n",
       " 'i94_nov16_sub.sas7bdat',\n",
       " 'i94_mar16_sub.sas7bdat',\n",
       " 'i94_jun16_sub.sas7bdat',\n",
       " 'i94_aug16_sub.sas7bdat',\n",
       " 'i94_may16_sub.sas7bdat',\n",
       " 'i94_jan16_sub.sas7bdat',\n",
       " 'i94_oct16_sub.sas7bdat',\n",
       " 'i94_jul16_sub.sas7bdat',\n",
       " 'i94_feb16_sub.sas7bdat',\n",
       " 'i94_dec16_sub.sas7bdat']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing cleaning tasks here\n",
    "\n",
    "files = os.listdir('../../data/18-83510-I94-Data-2016/')\n",
    "files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Dictionary - Immigaration Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cicid</td>\n",
       "      <td>Unique record ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i94yr</td>\n",
       "      <td>4 digit year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i94mon</td>\n",
       "      <td>Numeric month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i94cit</td>\n",
       "      <td>3 digit code for immigrant country of birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i94res</td>\n",
       "      <td>3 digit code for immigrant country of residence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i94port</td>\n",
       "      <td>Port of admission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arrdate</td>\n",
       "      <td>Arrival Date in the USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i94mode</td>\n",
       "      <td>Mode of transportation (1 = Air; 2 = Sea; 3 = ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i94addr</td>\n",
       "      <td>USA State of arrival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>depdate</td>\n",
       "      <td>Departure Date from the USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i94bir</td>\n",
       "      <td>Age of Respondent in Years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i94visa</td>\n",
       "      <td>Visa codes collapsed into three categories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>count</td>\n",
       "      <td>Field used for summary statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dtadfile</td>\n",
       "      <td>Character Date Field - Date added to I-94 Files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>visapost</td>\n",
       "      <td>Department of State where where Visa was issued</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>occup</td>\n",
       "      <td>Occupation that will be performed in U.S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>entdepa</td>\n",
       "      <td>Arrival Flag - admitted or paroled into the U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>entdepd</td>\n",
       "      <td>Departure Flag - Departed, lost I-94 or is dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>entdepu</td>\n",
       "      <td>Update Flag - Either apprehended, overstayed, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>matflag</td>\n",
       "      <td>Match flag - Match of arrival and departure re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>biryear</td>\n",
       "      <td>4 digit year of birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dtaddto</td>\n",
       "      <td>Character Date Field - Date to which admitted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gender</td>\n",
       "      <td>Non-immigrant sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>insnum</td>\n",
       "      <td>INS number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>airline</td>\n",
       "      <td>Airline used to arrive in U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>admnum</td>\n",
       "      <td>Admission Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>fltno</td>\n",
       "      <td>Flight number of Airline used to arrive in U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>visatype</td>\n",
       "      <td>Class of admission legally admitting the non-i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature                                         Description\n",
       "0      cicid                                   Unique record ID\n",
       "1      i94yr                                       4 digit year\n",
       "2     i94mon                                      Numeric month\n",
       "3     i94cit        3 digit code for immigrant country of birth\n",
       "4     i94res    3 digit code for immigrant country of residence\n",
       "5    i94port                                  Port of admission\n",
       "6    arrdate                            Arrival Date in the USA\n",
       "7    i94mode  Mode of transportation (1 = Air; 2 = Sea; 3 = ...\n",
       "8    i94addr                               USA State of arrival\n",
       "9    depdate                        Departure Date from the USA\n",
       "10    i94bir                         Age of Respondent in Years\n",
       "11   i94visa         Visa codes collapsed into three categories\n",
       "12     count                  Field used for summary statistics\n",
       "13  dtadfile    Character Date Field - Date added to I-94 Files\n",
       "14  visapost    Department of State where where Visa was issued\n",
       "15     occup           Occupation that will be performed in U.S\n",
       "16   entdepa   Arrival Flag - admitted or paroled into the U.S.\n",
       "17   entdepd  Departure Flag - Departed, lost I-94 or is dec...\n",
       "18   entdepu  Update Flag - Either apprehended, overstayed, ...\n",
       "19   matflag  Match flag - Match of arrival and departure re...\n",
       "20   biryear                              4 digit year of birth\n",
       "21   dtaddto  Character Date Field - Date to which admitted ...\n",
       "22    gender                                  Non-immigrant sex\n",
       "23    insnum                                         INS number\n",
       "24   airline                     Airline used to arrive in U.S.\n",
       "25    admnum                                   Admission Number\n",
       "26     fltno    Flight number of Airline used to arrive in U.S.\n",
       "27  visatype  Class of admission legally admitting the non-i..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_dict =pd.read_csv('Data dictionaries/immigration-data-dictionary.csv')\n",
    "imm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# columns with large amount of missing values as discovered by the exploratory analysis \n",
    "cols = ['occup', 'entdepu','insnum']\n",
    "\n",
    "# drop these columns\n",
    "new_immig_df = immigration_df.drop(*cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the new schema\n",
    "new_immig_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# drop duplicate entries\n",
    "new_immig_df = new_immig_df.dropDuplicates(['cicid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,096,313\n"
     ]
    }
   ],
   "source": [
    "# get a count after dropping duplicates\n",
    "print_formatted_float(new_immig_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# drop rows with missing values\n",
    "new_immig_df = new_immig_df.dropna(how='all', subset=['cicid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,096,313\n"
     ]
    }
   ],
   "source": [
    "# get a count after dropping rows with missing values\n",
    "print_formatted_float(new_immig_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in dataframe: 3,096,313\n",
      "Total records after cleaning: 3,096,313\n"
     ]
    }
   ],
   "source": [
    "# clean the immigration dataframe\n",
    "new_immigration_df = utility.clean_spark_immigration_data(immigration_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.Temperature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print temperature dataframe schema\n",
    "temperature_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Dictionary - Temperature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_dict =pd.read_csv('Data dictionaries/Temperature-data-dictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt</td>\n",
       "      <td>Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AverageTemperature</td>\n",
       "      <td>Global average land temperature in celsius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AverageTemperatureUncertainty</td>\n",
       "      <td>95% confidence interval around the average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>City</td>\n",
       "      <td>Name of City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Country</td>\n",
       "      <td>Name of Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>City Latitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>City Longitude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Feature                                 Description\n",
       "0                             dt                                        Date\n",
       "1             AverageTemperature  Global average land temperature in celsius\n",
       "2  AverageTemperatureUncertainty  95% confidence interval around the average\n",
       "3                           City                                Name of City\n",
       "4                        Country                             Name of Country\n",
       "5                       Latitude                               City Latitude\n",
       "6                      Longitude                              City Longitude"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "*Exploratory analysis showed some missing values of average temperature.Hence clean global temperature data by dropping the rows that has missing average temperature values and dropping duplicate columns.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in dataframe: 8,599,212\n",
      "Total records after dropping rows with missing values: 364,130\n",
      "Rows dropped after accounting for duplicates: 44,299\n"
     ]
    }
   ],
   "source": [
    "# clean the data by dropping rows with missing average temperature values and dropping duplicates\n",
    "new_temperature_df = utility.clean_spark_temperature_data(temperature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,891\n"
     ]
    }
   ],
   "source": [
    "# count the number of records in dataset\n",
    "print_formatted_float(demographics_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3.Demographics Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: double (nullable = true)\n",
      " |-- Male Population: integer (nullable = true)\n",
      " |-- Female Population: integer (nullable = true)\n",
      " |-- Total Population: integer (nullable = true)\n",
      " |-- Number of Veterans: integer (nullable = true)\n",
      " |-- Foreign-born: integer (nullable = true)\n",
      " |-- Average Household Size: double (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print demographics database schema\n",
    "demographics_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Dictionary - Demographics Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City</td>\n",
       "      <td>City Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State</td>\n",
       "      <td>US State where city is located</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Median Age</td>\n",
       "      <td>Median age of the population</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male Population</td>\n",
       "      <td>Count of male population</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female Population</td>\n",
       "      <td>Count of female population</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Total Population</td>\n",
       "      <td>Count of total population</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Number of Veterans</td>\n",
       "      <td>Count of total Veterans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Foreign born</td>\n",
       "      <td>Count of residents of the city that were not b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Average Household Size</td>\n",
       "      <td>Average city household size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>State Code</td>\n",
       "      <td>Code of the US state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Race</td>\n",
       "      <td>Respondent race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Count</td>\n",
       "      <td>Count of city's individual per race</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature                                        Description\n",
       "0                     City                                          City Name\n",
       "1                    State                     US State where city is located\n",
       "2               Median Age                       Median age of the population\n",
       "3          Male Population                           Count of male population\n",
       "4        Female Population                         Count of female population\n",
       "5         Total Population                          Count of total population\n",
       "6       Number of Veterans                            Count of total Veterans\n",
       "7             Foreign born  Count of residents of the city that were not b...\n",
       "8   Average Household Size                        Average city household size\n",
       "9               State Code                               Code of the US state\n",
       "10                    Race                                    Respondent race\n",
       "11                   Count                Count of city's individual per race"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_dict =pd.read_csv('Data dictionaries/Demographic data dictionary.csv')\n",
    "demo_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "*Exploratory analysis showed very minimal missing values in the demographics dataset.Hence clean demographics data by dropping the rows that contain missing values and dropping duplicate columns.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped with missing values: 16\n",
      "Rows dropped after accounting for duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# clean demographics data by dropping the rows that contain missing values and dropping duplicate columns\n",
    "new_demographics_df = utility.clean_spark_demographics_data(demographics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "\n",
    "\n",
    "### Database schema\n",
    "#### Fact Table\n",
    "- The immigration fact table is the fact table of the data model. This table's data comes from the immigration data sets and contains keys that links to the dimension tables. \n",
    "\n",
    "#### Dimension Tables\n",
    "- The *country* dimension table is made up of data from the global land temperatures by city and the immigration datasets. The combination of these two  datasets allows analysts to study correlations between global land temperatures and immigration patterns to the US.\n",
    "\n",
    "- The *us_demographics* dimension table comes from the demographics dataset and links to the immigration fact table at US state level. This dimension would allow analysts to get insights into migration patterns into the US based on demographics as well as overall population of states.It gives an insight on which states most immigrants are drawn towards\n",
    "\n",
    "- The *immigration_calendar* dimension table formed from the immigration datasets points towards arrival time of the immigrants\n",
    "\n",
    "- The *visa_type* dimension table comes from the immigration datasets and links to the immigaration making use of the visa_type_key.\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    " **The pipeline steps are as follows:**\n",
    "\n",
    "- Run functions.py and utility.py in the console to enable the functions for cleaning the datasets and creating the tables\n",
    "- Load the datasets\n",
    "- Cleaning the I94 Immigration data to create Spark dataframe for each month\n",
    "- Create visa_type dimension table\n",
    "- Create calendar dimension table\n",
    "- Extract clean global temperatures data\n",
    "- Create country dimension table\n",
    "- Create immigration fact table\n",
    "- Load demographics data\n",
    "- Clean demographics data\n",
    "- Create demographic dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Data model.png\" width=\"700\" height=\"700\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import image module\n",
    "from IPython.display import Image\n",
    "  \n",
    "# get the image\n",
    "Image(url=\"Data model.png\", width=700, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### I. Create the immigration calendar dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here\n",
    "\n",
    "def create_immigration_calendar_dimension(df, output_data):\n",
    "    \"\"\"This function creates an immigration calendar based on arrival date\n",
    "    \n",
    "    :param df: spark dataframe of immigration events\n",
    "    :param output_data: path to write dimension dataframe to\n",
    "    :return: spark dataframe representing calendar dimension\n",
    "    \"\"\"\n",
    "    # create a udf to convert arrival date in SAS format to datetime object\n",
    "    get_datetime = udf(lambda x: (dt.datetime(1960, 1, 1).date() + dt.timedelta(x)).isoformat() if x else None)\n",
    "    \n",
    "    # create initial calendar df from arrdate column\n",
    "    calendar_df = df.select(['arrdate']).withColumn(\"arrdate\", get_datetime(df.arrdate)).distinct()\n",
    "    \n",
    "    # expand df by adding other calendar columns\n",
    "    calendar_df = calendar_df.withColumn('arrival_day', dayofmonth('arrdate'))\n",
    "    calendar_df = calendar_df.withColumn('arrival_week', weekofyear('arrdate'))\n",
    "    calendar_df = calendar_df.withColumn('arrival_month', month('arrdate'))\n",
    "    calendar_df = calendar_df.withColumn('arrival_year', year('arrdate'))\n",
    "    calendar_df = calendar_df.withColumn('arrival_weekday', dayofweek('arrdate'))\n",
    "\n",
    "    # create an id field in calendar df\n",
    "    calendar_df = calendar_df.withColumn('id', monotonically_increasing_id())\n",
    "    \n",
    "    # write the calendar dimension to parquet file\n",
    "    partition_columns = ['arrival_year', 'arrival_month', 'arrival_week']\n",
    "    calendar_df.write.parquet(output_data + \"immigration_calendar\", partitionBy=partition_columns, mode=\"overwrite\")\n",
    "    \n",
    "    return calendar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "output_data = \"tables/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "calendar_df = create_immigration_calendar_dimension(new_immigration_df, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrdate</th>\n",
       "      <th>arrival_day</th>\n",
       "      <th>arrival_week</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_weekday</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>8589934592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>25769803776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-18</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>42949672960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>68719476736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>85899345920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      arrdate  arrival_day  arrival_week  arrival_month  arrival_year  \\\n",
       "0  2016-04-22           22            16              4          2016   \n",
       "1  2016-04-15           15            15              4          2016   \n",
       "2  2016-04-18           18            16              4          2016   \n",
       "3  2016-04-09            9            14              4          2016   \n",
       "4  2016-04-11           11            15              4          2016   \n",
       "\n",
       "   arrival_weekday           id  \n",
       "0                6   8589934592  \n",
       "1                6  25769803776  \n",
       "2                2  42949672960  \n",
       "3                7  68719476736  \n",
       "4                2  85899345920  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### II. Create the country dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_country_dimension_table(df, temp_df, output_data):\n",
    "    \"\"\"This function creates a country dimension from the immigration and global land temperatures data.\n",
    "    \n",
    "    :param df: spark dataframe of immigration events\n",
    "    :temp_df: spark dataframe of global land temperatures data.\n",
    "    :param output_data: path to write dimension dataframe to\n",
    "    :return: spark dataframe representing calendar dimension\n",
    "    \"\"\"\n",
    "    # get the aggregated temperature data\n",
    "    agg_temp = utility.aggregate_temperature_data(temp_df).toPandas()\n",
    "    # load the i94res to country mapping data\n",
    "    mapping_codes = pd.read_csv('i94.csv')\n",
    "    \n",
    "    @udf('string')\n",
    "    def get_country_average_temperature(name):\n",
    "        print(\"Processing: \", name)\n",
    "        avg_temp = agg_temp[agg_temp['Country']==name]['average_temperature']\n",
    "        \n",
    "        if not avg_temp.empty:\n",
    "            return str(avg_temp.iloc[0])\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    @udf()\n",
    "    def get_country_name(code):\n",
    "        name = mapping_codes[mapping_codes['code']==code]['name'].iloc[0]\n",
    "        \n",
    "        if name:\n",
    "            return name.title()\n",
    "        return None\n",
    "        \n",
    "    # select and rename i94res column\n",
    "    dim_df = df.select(['i94res']).distinct() \\\n",
    "                .withColumnRenamed('i94res', 'country_code')\n",
    "    \n",
    "    # create country_name column\n",
    "    dim_df = dim_df.withColumn('country_name', get_country_name(dim_df.country_code))\n",
    "    \n",
    "    # create average_temperature column\n",
    "    dim_df = dim_df.withColumn('average_temperature', get_country_average_temperature(dim_df.country_name))\n",
    "    \n",
    "    # write the dimension to a parquet file\n",
    "    dim_df.write.parquet(output_data + \"country\", mode=\"overwrite\")\n",
    "    \n",
    "    return dim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_dim_df = create_country_dimension_table(new_immigration_df, new_temperature_df, output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-------------------+\n",
      "|country_code| country_name|average_temperature|\n",
      "+------------+-------------+-------------------+\n",
      "|       692.0|      Ecuador|               null|\n",
      "|       299.0|     Mongolia|               null|\n",
      "|       576.0|  El Salvador|               null|\n",
      "|       735.0|  Montenegro |               null|\n",
      "|       206.0|    Hong Kong|               null|\n",
      "+------------+-------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_dim_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### III. Create the visa_type dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_visa_type_dimension_table(df, output_data):\n",
    "    \"\"\"This function creates a visa type dimension from the immigration data.\n",
    "    \n",
    "    :param df: spark dataframe of immigration events\n",
    "    :param output_data: path to write dimension dataframe to\n",
    "    :return: spark dataframe representing calendar dimension\n",
    "    \"\"\"\n",
    "    # create visatype df from visatype column\n",
    "    visatype_df = df.select(['visatype']).distinct()\n",
    "    \n",
    "    # add an id column\n",
    "    visatype_df = visatype_df.withColumn('visa_type_key', monotonically_increasing_id())\n",
    "    \n",
    "    # write dimension to parquet file\n",
    "    visatype_df.write.parquet(output_data + \"visatype\", mode=\"overwrite\")\n",
    "    \n",
    "    return visatype_df\n",
    "\n",
    "def get_visa_type_dimension(output_data):\n",
    "    return spark.read.parquet(output_data + \"visatype\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "|visatype|visa_type_key|\n",
      "+--------+-------------+\n",
      "|      F2| 103079215104|\n",
      "|     GMB| 352187318272|\n",
      "|      B2| 369367187456|\n",
      "|      F1| 498216206336|\n",
      "|     CPL| 601295421440|\n",
      "+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visatype_df = create_visa_type_dimension_table(new_immigration_df, output_data)\n",
    "visatype_df.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### IV. Create the demographics dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_demographics_dimension_table(df, output_data):\n",
    "    \"\"\"This function creates a us demographics dimension table from the us cities demographics data.\n",
    "    \n",
    "    :param df: spark dataframe of us demographics survey data\n",
    "    :param output_data: path to write dimension dataframe to\n",
    "    :return: spark dataframe representing demographics dimension\n",
    "    \"\"\"\n",
    "    dim_df = df.withColumnRenamed('Median Age','median_age') \\\n",
    "            .withColumnRenamed('Male Population', 'male_population') \\\n",
    "            .withColumnRenamed('Female Population', 'female_population') \\\n",
    "            .withColumnRenamed('Total Population', 'total_population') \\\n",
    "            .withColumnRenamed('Number of Veterans', 'number_of_veterans') \\\n",
    "            .withColumnRenamed('Foreign-born', 'foreign_born') \\\n",
    "            .withColumnRenamed('Average Household Size', 'average_household_size') \\\n",
    "            .withColumnRenamed('State Code', 'state_code')\n",
    "    # lets add an id column\n",
    "    dim_df = dim_df.withColumn('id', monotonically_increasing_id())\n",
    "    \n",
    "    # write dimension to parquet file\n",
    "    dim_df.write.parquet(output_data + \"demographics\", mode=\"overwrite\")\n",
    "    \n",
    "    return dim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>average_household_size</th>\n",
       "      <th>state_code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  median_age  male_population  \\\n",
       "0     Silver Spring       Maryland        33.8            40601   \n",
       "1            Quincy  Massachusetts        41.0            44129   \n",
       "2            Hoover        Alabama        38.5            38040   \n",
       "3  Rancho Cucamonga     California        34.5            88127   \n",
       "4            Newark     New Jersey        34.6           138040   \n",
       "\n",
       "   female_population  total_population  number_of_veterans  foreign_born  \\\n",
       "0              41862             82463                1562         30908   \n",
       "1              49500             93629                4147         32935   \n",
       "2              46799             84839                4819          8229   \n",
       "3              87105            175232                5821         33878   \n",
       "4             143873            281913                5829         86253   \n",
       "\n",
       "   average_household_size state_code                       Race  Count  id  \n",
       "0                    2.60         MD         Hispanic or Latino  25924   0  \n",
       "1                    2.39         MA                      White  58723   1  \n",
       "2                    2.58         AL                      Asian   4759   2  \n",
       "3                    3.18         CA  Black or African-American  24437   3  \n",
       "4                    2.73         NJ                      White  76402   4  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_dim_df = create_demographics_dimension_table(demographics_df, output_data)\n",
    "demographics_dim_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### V. Create the immigration Fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_immigration_fact_table(df, output_data):\n",
    "    \"\"\"This function creates an country dimension from the immigration and global land temperatures data.\n",
    "    \n",
    "    :param df: spark dataframe of immigration events\n",
    "    :param visa_type_df: spark dataframe of global land temperatures data.\n",
    "    :param output_data: path to write dimension dataframe to\n",
    "    :return: spark dataframe representing calendar dimension\n",
    "    \"\"\"\n",
    "    # get visa_type dimension\n",
    "    dim_df = get_visa_type_dimension(output_data).toPandas()\n",
    "    \n",
    "    @udf('string')\n",
    "    def get_visa_key(visa_type):\n",
    "        \"\"\"user defined function to get visa key\n",
    "        \n",
    "        :param visa_type: US non-immigrant visa type\n",
    "        :return: corresponding visa key\n",
    "        \"\"\"\n",
    "        key_series = dim_df[dim_df['visatype']==visa_type]['visa_type_key']\n",
    "        \n",
    "        if not key_series.empty:\n",
    "            return str(key_series.iloc[0])\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    # create a udf to convert arrival date in SAS format to datetime object\n",
    "    get_datetime = udf(lambda x: (dt.datetime(1960, 1, 1).date() + dt.timedelta(x)).isoformat() if x else None)\n",
    "    \n",
    "    # rename columns to align with data model\n",
    "    df = df.withColumnRenamed('cicid','record_id') \\\n",
    "            .withColumnRenamed('i94res', 'country_residence_code') \\\n",
    "            .withColumnRenamed('i94addr', 'state_code') \n",
    "    \n",
    "    # create visa_type key\n",
    "    df = df.withColumn('visa_type_key', get_visa_key('visatype'))\n",
    "    \n",
    "    # convert arrival date into datetime object\n",
    "    df = df.withColumn(\"arrdate\", get_datetime(df.arrdate))\n",
    "    \n",
    "    # write dimension to parquet file\n",
    "    df.write.parquet(output_data + \"immigration_fact\", mode=\"overwrite\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_fact_df = create_immigration_fact_table(new_immigration_df, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>country_residence_code</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>state_code</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "      <th>visa_type_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>5.542587e+10</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "      <td>884763262976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>305.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>5.542582e+10</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "      <td>884763262976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>496.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>5.542862e+10</td>\n",
       "      <td>00065</td>\n",
       "      <td>WB</td>\n",
       "      <td>738734374912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>558.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.543331e+10</td>\n",
       "      <td>00454</td>\n",
       "      <td>WB</td>\n",
       "      <td>738734374912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>596.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NAS</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>UP</td>\n",
       "      <td>5.540611e+10</td>\n",
       "      <td>00221</td>\n",
       "      <td>WT</td>\n",
       "      <td>884763262976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id   i94yr  i94mon  i94cit  country_residence_code i94port  \\\n",
       "0      299.0  2016.0     4.0   103.0                   103.0     NYC   \n",
       "1      305.0  2016.0     4.0   103.0                   103.0     NYC   \n",
       "2      496.0  2016.0     4.0   103.0                   103.0     CHI   \n",
       "3      558.0  2016.0     4.0   103.0                   103.0     SFR   \n",
       "4      596.0  2016.0     4.0   103.0                   103.0     NAS   \n",
       "\n",
       "      arrdate  i94mode state_code  depdate      ...       entdepd  matflag  \\\n",
       "0  2016-04-01      1.0         NY  20550.0      ...             O        M   \n",
       "1  2016-04-01      1.0         NY  20555.0      ...             O        M   \n",
       "2  2016-04-01      1.0         IL  20548.0      ...             O        M   \n",
       "3  2016-04-01      1.0         CA  20547.0      ...             O        M   \n",
       "4  2016-04-01      1.0         FL  20547.0      ...             N        M   \n",
       "\n",
       "   biryear   dtaddto gender airline        admnum  fltno  visatype  \\\n",
       "0   1962.0  06292016   None      OS  5.542587e+10  00087        WT   \n",
       "1   1953.0  06292016   None      OS  5.542582e+10  00087        WT   \n",
       "2   1952.0  06292016   None      OS  5.542862e+10  00065        WB   \n",
       "3   1974.0  06292016      M      LH  5.543331e+10  00454        WB   \n",
       "4   1992.0  06292016      M      UP  5.540611e+10  00221        WT   \n",
       "\n",
       "  visa_type_key  \n",
       "0  884763262976  \n",
       "1  884763262976  \n",
       "2  738734374912  \n",
       "3  738734374912  \n",
       "4  884763262976  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_fact_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_fact_df.createOrReplaceTempView('immigration_fact_table')\n",
    "visatype_df.createOrReplaceTempView('visatype_table')\n",
    "demographics_dim_df.createOrReplaceTempView('demographics_dim_table')\n",
    "country_dim_df.createOrReplaceTempView('country_dim_table')\n",
    "calendar_df.createOrReplaceTempView('calendar_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Query on count of people of different visatypes living in a particular state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "query= spark.sql('''SELECT vt.visatype,dg.state,count(*)\n",
    "     FROM immigration_fact_table if\n",
    "     \n",
    "     JOIN  visatype_table vt\n",
    "     ON vt.visa_type_key = if.visa_type_key\n",
    "     JOIN demographics_dim_table dg\n",
    "     ON dg.state_code =if.state_code\n",
    "     GROUP BY 1,2\n",
    "     ORDER by 3 DESC\n",
    "     ''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+\n",
      "|visatype|     state| count(1)|\n",
      "+--------+----------+---------+\n",
      "|      WT|California|132392572|\n",
      "|      B2|California|116932452|\n",
      "|      B2|   Florida| 70838424|\n",
      "|      WT|   Florida| 55476912|\n",
      "|      WB|California| 34409076|\n",
      "|      B1|California| 24462412|\n",
      "|      B2|     Texas| 17170335|\n",
      "|      WT|  New York| 17127828|\n",
      "|      B2|  New York|  9120600|\n",
      "|      WT|     Texas|  7740642|\n",
      "|      F1|California|  6319924|\n",
      "|      B1|   Florida|  5860134|\n",
      "|      WB|     Texas|  5396118|\n",
      "|      B1|     Texas|  5253339|\n",
      "|      WB|   Florida|  4164054|\n",
      "|      B2|  Illinois|  2796066|\n",
      "|      WT|    Nevada|  2714400|\n",
      "|      B2|New Jersey|  2250531|\n",
      "|      E2|California|  2025296|\n",
      "|      WT|  Illinois|  2001090|\n",
      "+--------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Query on the count of people of particular visatype based on their age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "query1= spark.sql('''SELECT vt.visatype,if.biryear,count(*)\n",
    "     FROM immigration_fact_table if     \n",
    "     JOIN visatype_table vt\n",
    "     ON vt.visa_type_key = if.visa_type_key\n",
    "     GROUP BY 1,2\n",
    "     ORDER by 3 DESC\n",
    "     ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+\n",
      "|visatype|biryear|count(1)|\n",
      "+--------+-------+--------+\n",
      "|      WT| 1986.0|   32782|\n",
      "|      WT| 1987.0|   30002|\n",
      "|      WT| 1985.0|   29931|\n",
      "|      WT| 1988.0|   29556|\n",
      "|      WT| 1984.0|   28124|\n",
      "|      WT| 1989.0|   27726|\n",
      "|      WT| 1983.0|   26872|\n",
      "|      WT| 1982.0|   25777|\n",
      "|      WT| 1990.0|   25684|\n",
      "|      WT| 1966.0|   25284|\n",
      "|      WT| 1981.0|   24955|\n",
      "|      WT| 1976.0|   24873|\n",
      "|      B2| 1982.0|   24682|\n",
      "|      B2| 1983.0|   24533|\n",
      "|      B2| 1981.0|   24148|\n",
      "|      WT| 1980.0|   24075|\n",
      "|      B2| 1984.0|   23671|\n",
      "|      B2| 1985.0|   23649|\n",
      "|      B2| 1980.0|   23516|\n",
      "|      B2| 1986.0|   23271|\n",
      "+--------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.2 Data Quality Checks\n",
    "The data quality checks are done to ensure that the ETL has created the fact table  and the dimension tables with adequate amount of data.\n",
    " \n",
    "#### Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Check 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for immigration_fact with 3,096,313 records.\n",
      "Data quality check passed for visa_type_dim with 17 records.\n",
      "Data quality check passed for calendar_dim with 30 records.\n",
      "Data quality check passed for usa_demographics_dim with 2,891 records.\n",
      "Data quality check passed for country_dim with 229 records.\n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "\n",
    "table_dfs = {\n",
    "    'immigration_fact': immigration_fact_df,\n",
    "    'visa_type_dim': visatype_df,\n",
    "    'calendar_dim': calendar_df,\n",
    "    'usa_demographics_dim': demographics_dim_df,\n",
    "    'country_dim': country_dim_df\n",
    "}\n",
    "for table_name, table_df in table_dfs.items():\n",
    "    functions.quality_checks(table_df, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Check 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "immigrations_calender_check1 = spark.sql(\"\"\"\n",
    "    SELECT  COUNT(*)\n",
    "    FROM calendar_table\n",
    "        WHERE   id IS NULL OR id == \"\" OR\n",
    "                arrdate IS NULL OR arrdate == \"\" OR\n",
    "                arrival_year IS NULL OR arrival_year == \"\" OR\n",
    "                arrival_month IS NULL OR arrival_month == \"\" OR\n",
    "                arrival_day IS NULL OR arrival_day == \"\" OR\n",
    "                arrival_week IS NULL OR arrival_week == \"\" OR\n",
    "                arrival_weekday IS NULL OR arrival_weekday == \"\"\n",
    "\"\"\")\n",
    "immigrations_calender_check1.show(1)\n",
    "immigrations_calender_check1.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      30|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "immigrations_calender_check2 = spark.sql(\"\"\"\n",
    "    SELECT  COUNT(*)\n",
    "    FROM calendar_table\n",
    "\"\"\")\n",
    "immigrations_calender_check2.show(1)\n",
    "immigrations_calender_check2.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS: {'immigrations_count': 30, 'immigrations': 'OK'}\n"
     ]
    }
   ],
   "source": [
    "results={}\n",
    "if immigrations_calender_check1.collect()[0][0] > 0 & immigrations_calender_check2.collect()[0][0] < 1:\n",
    "    results['immigrations_count'] = immigrations_calender_check2.collect()[0][0]\n",
    "    results['immigrations'] = \"Not OK\"\n",
    "else:\n",
    "    results['immigrations_count'] = immigrations_calender_check2.collect()[0][0]\n",
    "    results['immigrations'] = \"OK\"\n",
    "\n",
    "print(f\"RESULTS: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 5: Complete Project Write Up\n",
    "\n",
    "#### Rationale for the choice of tools and technologies for the project\n",
    " \n",
    " Apache Spark was the main tool used because it is able to handle files of different format and of large amounts of data.A faster unified analytics engine to handle big data\n",
    "\n",
    "#### Propose how often the data should be updated and why.\n",
    " \n",
    " The available I94 immigration dataset is being updated on a monthly basis . Thus our data also require monthly update.\n",
    "\n",
    "#### Write a description of how you would approach the problem differently under the following scenarios:\n",
    " 1. The data was increased by 100x.\n",
    "     - Spark has the advantage of being highly scalable. So if the data is increased, we can handle it by increasing the number of our cluser nodes       \n",
    " 2. The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "     -  In this kind of a situation,we can use  Apache Airflow to schedule and run data pipelines.\n",
    " 3. The database needed to be accessed by 100+ people.\n",
    "     -   Amazon Redshift can be made use of in such a scenario.The analytics database can be shifted to Amazon Redshift\n",
    " ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
